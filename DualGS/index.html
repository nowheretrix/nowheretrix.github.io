<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Robust Dual Gaussian Splatting for Immersive Human-centric Volumetric Videos">
    <meta name="author" content="Yuheng Jiang, Zhehao Shen, Yu Hong, Chengcheng Guo, Yize Wu, Yingliang Zhang, Jingyi Yu, Lan Xu">

    <title>Robust Dual Gaussian Splatting for Immersive Human-centric Volumetric Videos</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Robust Dual Gaussian Splatting for Immersive Human-centric Volumetric Videos</h2>
    <hr>
    <h3 class="nerf_subheader_v2">SIGGRAPH Asia 2024 (TOG)</h3>
    <p class="authors">
        <a href="https://nowheretrix.github.io/"> Yuheng Jiang</a>,
        <a href="https://github.com/moqiyinlun/"> Zhehao Shen</a>,
        <a href="https://github.com/xyi1023"> Yu Hong</a>,
        <a > Chengcheng Guo</a>,
        <a > Yize Wu</a>,
        <a href="https://cn.linkedin.com/in/yingliangzhang"> Yingliang Zhang</a>,
        <a href="https://sist.shanghaitech.edu.cn/2020/0707/c7499a53862/page.htm"> Jingyi Yu</a>,
        <a href="http://xu-lan.com/"> Lan Xu</a>
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <!-- <a class="btn btn-primary" href="https://arxiv.org/abs/2312.03461">Paper</a> -->
        <!-- <a class="btn btn-primary" href="https://github.com/moqiyinlun/HiFi4G_Dataset">Dataset</a> -->
    </div>
</div>

<div class="container">

<!-- Carousel Structure -->
<div id="videoCarousel" class="carousel slide" data-ride="carousel" data-interval="12000">
    <!-- Progress Bar Style Indicators -->
    <div class="progress-indicator">
        <div class="progress-bar">
            <div class="progress"></div>
        </div>
    </div>
    <div class="carousel-inner">
        <!-- Video Items -->
        <div class="carousel-item active">
            <video class="a16x9demo" loop muted playsinline width="100%" height="654">
                <source src="D:/nowhere/z主页/nowheretrix.github.io/DualGS/video/hu_flute2_more_fvv_new.mp4" type="video/mp4">
            </video>
        </div>
        <div class="carousel-item">
            <video class="a16x9demo" loop muted playsinline width="100%" height="654">
                <source src="https://zhenx.me/4k4d.assets/demo_videos/outdoor/actor1_4/01_crop.mp4" type="video/mp4">
            </video>
        </div>
        <div class="carousel-item">
            <video class="a16x9demo" loop muted playsinline width="100%" height="654">
                <source src="https://zhenx.me/4k4d.assets/demo_videos/outdoor/actor1_4/01_crop.mp4" type="video/mp4">
            </video>
        </div>
        <div class="carousel-item">
            <video class="a16x9demo" loop muted playsinline width="100%" height="654">
                <source src="https://zhenx.me/4k4d.assets/demo_videos/outdoor/actor5_6/01_crop.mp4" type="video/mp4">
            </video>
        </div>
    </div>

    <!-- Custom Styled Navigation Buttons -->
    <a class="carousel-control-prev" href="#videoCarousel" role="button" data-slide="prev">
        <span class="carousel-control-prev-icon custom-nav-icon" aria-hidden="true"></span>
        <span class="sr-only">Previous</span>
    </a>
    <a class="carousel-control-next" href="#videoCarousel" role="button" data-slide="next">
        <span class="carousel-control-next-icon custom-nav-icon" aria-hidden="true"></span>
        <span class="sr-only">Next</span>
    </a>
</div>

<!-- CSS for Enhanced UI -->
<style>
    .custom-nav-icon {
        background-image: none;
        display: inline-block;
        width: 35px;
        height: 35px;
        border: 2px solid #007bff;
        border-radius: 50%;
        background-color: rgba(0, 123, 255, 0.7);
        position: relative;
        box-shadow: 0 0 15px rgba(0, 0, 0, 0.3);
        transition: all 0.3s ease;
    }

    .custom-nav-icon:before {
        content: '';
        display: block;
        width: 8px;
        height: 8px;
        border-top: 2px solid #fff;
        border-right: 2px solid #fff;
        position: absolute;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%) rotate(45deg);
    }

    .carousel-control-prev .custom-nav-icon:before {
        transform: translate(-50%, -50%) rotate(-135deg);
    }

    .progress-indicator {
        position: absolute;
        bottom: 15px;
        left: 50%;
        transform: translateX(-50%);
        width: 80%;
        height: 5px;
        background-color: #e9ecef;
        border-radius: 10px;
        overflow: hidden;
        box-shadow: inset 0 1px 3px rgba(0, 0, 0, 0.2);
    }

    .progress-bar {
        position: relative;
        width: 100%;
        height: 100%;
    }

    .progress {
        height: 100%;
        background-color: #007bff;
        transition: width 0.4s ease;
    }
</style>

<!-- JavaScript to Update Progress Bar -->
<script>
    document.addEventListener('DOMContentLoaded', function() {
        var carousel = document.getElementById('videoCarousel');
        var progress = document.querySelector('.progress');

        // Initial update of progress bar
        updateProgressBar(0);

        // Event listener for slide change
        carousel.addEventListener('slide.bs.carousel', function(e) {
            updateProgressBar(e.to);
        });

        function updateProgressBar(currentIndex) {
            var totalItems = document.querySelectorAll('#videoCarousel .carousel-item').length;
            var widthPercentage = ((currentIndex + 1) / totalItems) * 100;
            progress.style.width = widthPercentage + '%';
        }
    });
</script>

    
    <div class="section">
        
        <div class="vcontainer">
            <!-- <iframe class='video' src="https://www.youtube.com/embed/8F-D7kaZmJk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->
            <iframe class='video' src="https://www.youtube.com/embed/917WVr2EHh4?si=3EXqYHKyg38ep1yb" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
        
        <hr>
       
        <p>
            DualGS serves as a “ticket” to a virtual world, offering immersive, high-fidelity viewing of multiple musicians performing.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/teaser.jpg" style="width:100%; margin-right:-10px; margin-top:5px;">
        </div> 
    </div>

    

    <div class="section">
        <h2>Pipeline</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/pipeline.png" style="width:100%; margin-right:-10px; margin-top:-10px;">
        </div> 
        <p>
             The keyframe based non-rigid tracking establishes a coarse deformation graph and tracks the motions for Gaussian optimization. Subsequently, HiFi4G initializes first frame Gaussians from NeuS2 and constructs a fine-grained Gaussian graph to enhance temporal coherence. We then employ the ED graph to warp 4D Gaussians, applying both E_smooth and E_temp constraints to the Gaussian graph, which yields spatial-temporally compact and compression-friendly 4D Gaussians, thus facilitating efficient compression.
        </p>
       
    </div>
    <div class="section">
        <h2>Result</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/gallery.png" style="width:100%; margin-right:-10px; margin-top:-10px;">
        </div>
        <p>
            Here are our rendering results. HiFi4G delivers real-time high-fidelity rendering of human performance across challenging motions, such as playing instruments, dancing and changing clothes.
        </p>
    </div>

    <div class="section">
        <h2>Acknowledgements</h2>
        <hr>
        <p>
            The authors would like to thank Zitong Hu, Shang Zhang, and Xi Chen from ShanghaiTech University for processing the dataset. We are grateful to Hao Liu for insightful discussions. We also thank the reviewers for their feedback. This work was supported by National Key R&D Program of China (2022YFF0902301), Shanghai Local college capacity building program (22010502800). We also acknowledge support from Shanghai Frontiers Science Center of Human-centered Artificial Intelligence (ShangHAI).
        </p>
    </div>
<!-- 
    <div class="section">
        <h2>Results</h2>
        <hr>

        <div class="col justify-content-center text-center">
            <img src="img/progress.png" style="width:100%; margin-right:-10px; margin-top:10px;">

        <p>
            Optimization progress. We show results of our fine-tuning (top) and optimizing a <b>NeRF</b> (bottom) with different time periods. Our <b>0-min</b> result refers to the initial output from our network inference. Note that our <b>18-min</b> results are already much better than the <b>215-min</b> NeRF results. PSNRs of the image crops are shown in the figure.
        </p>

        <div class="col justify-content-center text-center">
            <img src="img/result.png" style="width:100%; margin-right:-10px; margin-top:10px;">

        <p>
            Rendering quality comparison. On the left, we show rendering results of our method and concurrent neural rendering methods PixelNeRF, IBRNet by directly running the networks. We show our 15-min fine-tuning results and NeRF's  10.2h-optimization results on the right.
        </p>
    </div>

    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/abs/2103.15595"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>  -->

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @InProceedings{Jiang_2024_CVPR, 
                author = {Jiang, Yuheng and Shen, Zhehao and Wang, Penghao and 
                          Su, Zhuo and Hong, Yu and Zhang, Yingliang and Yu, Jingyi and Xu, Lan}, 
                title = {HiFi4G: High-Fidelity Human Performance Rendering 
                         via Compact Gaussian Splatting}, 
                booktitle = {Proceedings of the IEEE/CVF Conference on 
                             Computer Vision and Pattern Recognition (CVPR)}, 
                month = {June}, 
                year = {2024}, 
                pages = {19734-19745} 
            }
        </div>
    </div>

    <hr>

    <footer>
        <p>Send feedback and questions to <a href="https://nowheretrix.github.io/">Yuheng Jiang</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
