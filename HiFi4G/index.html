<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting">
    <meta name="author" content="Yuheng Jiang, Zhehao Shen, Penghao Wang, Zhuo Su, Yu Hong, Yingliang Zhang, Jingyi Yu, Lan Xu">

    <title>HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian Splatting</h2>
        <!-- <h3>ICCV 2021</h3> -->
           <!-- <p class="abstract">4D modeling of human-object interactions from monocular RGBD camera.</p> -->
    <hr>
    <!-- <h3 class="nerf_subheader_v2">CVPR 2023</h3> -->
    <p class="authors">
        <a href="https://nowheretrix.github.io/"> Yuheng Jiang</a>,
        <a > Zhehao Shen</a>,
        <a > Penghao Wang</a>,
        <a > Zhuo Su</a>,
        <a > Yu Hong</a>,
        <a href="https://cn.linkedin.com/in/yingliangzhang"> Yingliang Zhang</a>,
        <a href="https://sist.shanghaitech.edu.cn/2020/0707/c7499a53862/page.htm"> Jingyi Yu</a>,
        <a href="http://xu-lan.com/"> Lan Xu</a>
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://arxiv.org/abs/2304.03184">Arxiv</a>
        <!-- <a class="btn btn-primary" href="https://nowheretrix.github.io/neuralfusion/">Sequences(coming soon)</a> -->
    </div>
</div>

<div class="container">
    <div class="section">
        
        <div class="vcontainer">
            <!-- <iframe class='video' src="https://www.youtube.com/embed/8F-D7kaZmJk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->
            <iframe class='video' src="https://www.youtube.com/embed/917WVr2EHh4?si=3EXqYHKyg38ep1yb" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
        
        <hr>
       
        <p>
            We have recently seen tremendous progress in photo-real human modeling and rendering. Yet, efficiently rendering realistic human performance and integrating it into the rasterization pipeline remains challenging. 
In this paper, we present HiFi4G, an explicit and compact Gaussian-based approach for high-fidelity human performance rendering from dense footage. Our core intuition is to marry the 3D Gaussian representation with non-rigid tracking, achieving a compact and compression-friendly representation.
We first propose a dual-graph mechanism to obtain motion priors, with a coarse deformation graph for effective initialization and a fine-grained Gaussian graph to enforce subsequent constraints. 
Then, we utilize a 4D Gaussian optimization scheme with adaptive spatial-temporal regularizers to effectively balance the non-rigid prior and Gaussian updating.
We also present a companion compression scheme with residual compensation for immersive experiences on 
various platforms. It achieves a substantial compression rate of approximately 25 times, with less than 2MB of storage per frame.
Extensive experiments demonstrate the effectiveness of our approach, which significantly outperforms existing approaches in terms of optimization speed, rendering quality, and storage overhead.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/teaser.png" style="width:100%; margin-right:-10px; margin-top:5px;">
        </div> 
    </div>



    <div class="section">
        <h2>Pipeline</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/pipeline.png" style="width:100%; margin-right:-10px; margin-top:-10px;">
        </div> 
        <p>
             The keyframe based non-rigid tracking establishes a coarse deformation graph and tracks the motions for Gaussian optimization. Subsequently, HiFi4G initializes first frame Gaussians from NeuS2 and constructs a fine-grained Gaussian graph to enhance temporal coherence. We then employ the ED graph to warp 4D Gaussians, applying both E_smooth and E_temp constraints to the Gaussian graph, which yields spatial-temporally compact and compression-friendly 4D Gaussians, thus facilitating efficient compression.
        </p>
       
    </div>
    <div class="section">
        <h2>Result</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/gallery.png" style="width:100%; margin-right:-10px; margin-top:-10px;">
        </div>
        <p>
            Here are our rendering results. HiFi4G delivers real-time high-fidelity rendering of human performance across challenging motions, such as playing instruments, dancing and changing clothes.
        </p>
    </div>
   
<!-- 
    <div class="section">
        <h2>Results</h2>
        <hr>

        <div class="col justify-content-center text-center">
            <img src="img/progress.png" style="width:100%; margin-right:-10px; margin-top:10px;">

        <p>
            Optimization progress. We show results of our fine-tuning (top) and optimizing a <b>NeRF</b> (bottom) with different time periods. Our <b>0-min</b> result refers to the initial output from our network inference. Note that our <b>18-min</b> results are already much better than the <b>215-min</b> NeRF results. PSNRs of the image crops are shown in the figure.
        </p>

        <div class="col justify-content-center text-center">
            <img src="img/result.png" style="width:100%; margin-right:-10px; margin-top:10px;">

        <p>
            Rendering quality comparison. On the left, we show rendering results of our method and concurrent neural rendering methods PixelNeRF, IBRNet by directly running the networks. We show our 15-min fine-tuning results and NeRF's  10.2h-optimization results on the right.
        </p>
    </div>

    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/abs/2103.15595"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>  -->

    <!-- <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @article{jiang2022neuralfusion,
                title={NeuralFusion: Neural Volumetric Rendering under Human-object Interactions},
                author={Jiang, Yuheng and Jiang, Suyi and Sun, Guoxing and Su, Zhuo and Guo, Kaiwen 
                        and Wu, Minye and Yu, Jingyi and Xu, Lan},
                journal={arXiv preprint arXiv:2202.12825},
                year={2022}
              }
        </div>
    </div>

    <hr> -->
    <hr>

    <footer>
        <p>Send feedback and questions to <a href="https://nowheretrix.github.io/">Yuheng Jiang</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
